{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Text Mining-NLP- Text Clustering Use Case",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahsanuamal/ahsanuamal/blob/main/Text_Mining_NLP_Text_Clustering_Use_Case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am-_A8L24id7"
      },
      "source": [
        "# Lab 06 - DOCUMENT CLUSTERING "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK8rnr1q4ieW"
      },
      "source": [
        "#Release: 1.2108.0101"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QWNHbRedyuM"
      },
      "source": [
        "## Library Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqN-SnP8Z-Zw"
      },
      "source": [
        "<br>\n",
        " \n",
        "***If you use Google Colab, install sastrawi package***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZLJn6Ry7IBv"
      },
      "source": [
        "!pip install sastrawi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXFx2tZK4ifN"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### Import required library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CejV7KDD4ifY"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        " \n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import MDS\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ0t-sAleDVP"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### Download punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnMijOCkZEsA"
      },
      "source": [
        "<br>\n",
        " \n",
        "***If you use Google Colab, download stopwords dan punkt package***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfbPHY8f5CXB"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wCb-uk4eKCH"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### User defined function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ddSVT9PeQNZ"
      },
      "source": [
        "def tokenize_clean(text):\n",
        "    \n",
        "    #tokenisasi\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word\n",
        "        in nltk.word_tokenize(sent)]\n",
        "    \n",
        "    #clean token from numeric and other character like puntuation\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "            \n",
        "    return filtered_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCKKxFAfszP8"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('indonesian')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGNZ1XQEgDP7"
      },
      "source": [
        "def remove_stopwords(tokenized_text):\n",
        "    \n",
        "    cleaned_token = []\n",
        "    for token in tokenized_text:\n",
        "        if token not in stopwords:\n",
        "            cleaned_token.append(token)\n",
        "            \n",
        "    return cleaned_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBWuiz7KsTJZ"
      },
      "source": [
        "#stem using Sastrawi StemmerFactory\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJCRTxkLgJ2a"
      },
      "source": [
        "def stemming_text(tokenized_text):\n",
        "    stems = []\n",
        "    for token in tokenized_text:\n",
        "        stems.append(stemmer.stem(token))\n",
        "\n",
        "    return stems\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTXBhCEqgNC1"
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    result_step1 = tokenize_clean(text)\n",
        "    result_step2 = remove_stopwords(result_step1)\n",
        "    result = stemming_text(result_step2)\n",
        "            \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--whSIZjEfoJ"
      },
      "source": [
        "#### text_preprocessing Function Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUM4E0EkEpNR"
      },
      "source": [
        "dataset = 'Di daerah, alokasi anggaran Transfer ke Daerah dan Dana Desa (TKDD) ditetapkan sebesar Rp766,16 triliun pada APBN 2018'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmR6faqDttXl"
      },
      "source": [
        "text_prep_result = text_preprocessing(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkZEo9NGuByR"
      },
      "source": [
        "len(text_prep_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGptUe89uD7G"
      },
      "source": [
        "text_prep_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEQ8uvueeZGg"
      },
      "source": [
        "<br>\n",
        "\n",
        "## Dataset Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjpI9QIGtKlq"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### Download dataset from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQAC2WpSK54J"
      },
      "source": [
        "!mkdir -p dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvPQX6UTJvKk"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/project303/dataset/master/Berita.txt -P dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZL1CSpdLipk"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/project303/dataset/master/Judul-Berita.txt -P dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WFyI9lL7ymG"
      },
      "source": [
        "!ls dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deC2gfLIFf9I"
      },
      "source": [
        "! head dataset/Judul-Berita.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJIo40osesJ-"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqVDukxJ4if3"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 01 - Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gxOXZNS4igD"
      },
      "source": [
        "#load titles\n",
        "article_titles = open('dataset/Judul-Berita.txt').read().split('\\n')\n",
        "len(article_titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeGmF-y_4igb"
      },
      "source": [
        "article_titles[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPclpSke4ihP"
      },
      "source": [
        "article_content = open('dataset/Berita.txt', encoding=\"utf8\").read().split('BERHENTI DISINI')\n",
        "len(article_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMM-TW2DfaCo"
      },
      "source": [
        "article_content[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbeYLFPq0BWu"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 02 - Cleanup dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU8Bb2htD0Iv"
      },
      "source": [
        "Cleanup dataset from HTML tags using BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zCFipv24iiA"
      },
      "source": [
        "article_clean = []\n",
        "for text in article_content:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    article_clean.append(text)\n",
        "  \n",
        "article_content = article_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyeIrdfA0RVl"
      },
      "source": [
        "article_content[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeaC7HBk0uHZ"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGeNwTPP4imU"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 03 - TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4T2NTnc4imX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvq1LyX6q-yh"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.1,\n",
        "                                   max_features=200000,\n",
        "                                   use_idf=True,\n",
        "                                   tokenizer=text_preprocessing,\n",
        "                                   ngram_range=(1,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckykQ9854inE"
      },
      "source": [
        "get_ipython().magic(u'time tfidf_features = tfidf_vectorizer.fit_transform(article_content)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EvaIW_B4inQ"
      },
      "source": [
        "print(tfidf_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn_8Dy6Y4inq"
      },
      "source": [
        "bag_of_words = tfidf_vectorizer.get_feature_names()\n",
        "len(bag_of_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSHxAUAwjh93"
      },
      "source": [
        "bag_of_words[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlNz96eN10SZ"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZqZ7cVK4ioT"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 04 - K-Means Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZqngwsH4ioY"
      },
      "source": [
        "num_clusters = 3\n",
        "model_km = KMeans(n_clusters=num_clusters, random_state=1000)\n",
        "\n",
        "#train the model\n",
        "get_ipython().magic(u'time model_km.fit(tfidf_features)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSGO7HIJHydK"
      },
      "source": [
        "clusters = model_km.labels_.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397Kw44gI4tp"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 05 - View The Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjG9ToYUIBFt"
      },
      "source": [
        "article_no = []\n",
        "for i in range(1, len(article_titles)+1):\n",
        "    article_no.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1nJ4nlD4ioj"
      },
      "source": [
        "article_cluster = { 'title': article_titles, 'no': article_no, 'article': article_content, 'cluster': clusters }\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df = pd.DataFrame(article_cluster, index = [clusters] , columns = ['no', 'title', 'cluster'])\n",
        "df.sort_index()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldEYgaQuyOyh"
      },
      "source": [
        "df['cluster'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZp_t_XsKoTb"
      },
      "source": [
        "Top words per cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylv8xThYLOLF"
      },
      "source": [
        "df_bow = pd.DataFrame({'words': bag_of_words}, index = bag_of_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OECnFT0d4io5"
      },
      "source": [
        "print(\"Top words per cluster:\")\n",
        "\n",
        "#sort cluster centers by proximity to centroid\n",
        "order_centroids = model_km.cluster_centers_.argsort()[:, ::-1] \n",
        "\n",
        "for i in range(num_clusters):\n",
        "    print(\"Cluster %d words:\" % i, end='')\n",
        "    \n",
        "    for ind in order_centroids[i, :10]: #replace 6 with n words per cluster\n",
        "        print(' %s' % df_bow.loc[bag_of_words[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
        "    print() #add whitespace\n",
        "    print() #add whitespace\n",
        "    \n",
        "    print(\"Cluster %d titles:\" % i, end='')\n",
        "    for title in df.loc[i]['title'].values.tolist():\n",
        "        print(' %s,' % title, end='')\n",
        "    print() #add whitespace\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU7TPrum2xKR"
      },
      "source": [
        "<br>\n",
        "\n",
        "## Cluster Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvoke3mc4ipE"
      },
      "source": [
        "### Step 07 - Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BJdhfry4ipH"
      },
      "source": [
        "similarity_distance = 1 - cosine_similarity(tfidf_features)\n",
        "print(type(similarity_distance))\n",
        "print(similarity_distance.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cN0J7bv4ipQ"
      },
      "source": [
        "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
        "get_ipython().magic(u'time pos = mds.fit_transform(similarity_distance)  # shape (n_components, n_samples)')\n",
        "print(pos.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcJVsLncNLvf"
      },
      "source": [
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgXDpNs5NS3I"
      },
      "source": [
        "xs, ys = pos[:, 0], pos[:, 1]\n",
        "print(type(xs))\n",
        "xs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXtIwsJJ4ipZ"
      },
      "source": [
        "#set up colors per clusters using a dict\n",
        "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJZjEib4ipl"
      },
      "source": [
        "#set up cluster names using a dict\n",
        "cluster_names = {0: 'Ekonomi', \n",
        "                 1: 'Kriminal',\n",
        "                 2: 'Olahraga'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLbbVwCk4ipu"
      },
      "source": [
        "matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB77ozHY4ip6"
      },
      "source": [
        "#some ipython magic to show the matplotlib plots inline\n",
        "get_ipython().magic(u'matplotlib inline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTVfx-_q4iqL"
      },
      "source": [
        "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
        "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=article_titles)) \n",
        "\n",
        "print(df[1:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDYD4rP44iqZ"
      },
      "source": [
        "# group by cluster\n",
        "# this generate {name:group(which is a dataframe)}\n",
        "groups = df.groupby('label')\n",
        "print(groups.groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uk8BI2J4iqo"
      },
      "source": [
        "# set up plot\n",
        "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
        "# ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
        "\n",
        "#iterate through groups to layer the plot\n",
        "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
        "# ms: marker size\n",
        "for name, group in groups:\n",
        "    #print(\"*******\")\n",
        "    #print(\"group name \" + str(name))\n",
        "    #print(group)\n",
        "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=20, \n",
        "            label=cluster_names[name], color=cluster_colors[name], \n",
        "            mec='none')\n",
        "    ax.set_aspect('auto')\n",
        "    ax.tick_params(        axis= 'x',          # changes apply to the x-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        bottom='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelbottom='off')\n",
        "    ax.tick_params(        axis= 'y',         # changes apply to the y-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        left='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelleft='off')\n",
        "    \n",
        "ax.legend(numpoints=1)  #show legend with only 1 point\n",
        "\n",
        "#add label in x,y position with the label as the film title\n",
        "for i in range(len(df)):\n",
        "    ax.text(df.loc[i]['x'], df.loc[i]['y'], df.loc[i]['title'], size=10)  \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efm7P64p4iqz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGS4xMJR4iq7"
      },
      "source": [
        "article_similarities = cosine_similarity(tfidf_features[0], tfidf_features).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKJwhCV5QOg-"
      },
      "source": [
        "article_similarities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNHB-177UGKe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Jx_TtCUysD"
      },
      "source": [
        "Simple example cosine similarities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdJN7fzISbtv"
      },
      "source": [
        "search_terms = 'tomatoes is a fruit'\n",
        "documents = ['cars drive on the road', 'tomatoes are actually fruit']\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True)\n",
        "doc_vectors = vectorizer.fit_transform(documents)\n",
        "search_vector = vectorizer.transform([search_terms])\n",
        "\n",
        "cosine_similarities = cosine_similarity(search_vector, doc_vectors).flatten()\n",
        "document_scores = [item.item() for item in cosine_similarities]\n",
        "\n",
        "document_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La3m2JpqW3sw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Nxj-C3W3kc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQPwPTt8W1yQ"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "**Revision History:**\n",
        "\n",
        "Release: 1.2108.0101\n",
        "*   Cleanup the code\n",
        "*   Add cossine simimilarities\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4iZnKUkXQ91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}